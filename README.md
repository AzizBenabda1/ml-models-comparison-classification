# Machine Learning Models Comparison: KNN, SVM, Decision Tree, XGBoost, Random Forest

This project presents a comprehensive comparison of multiple supervised machine learning algorithms applied to a structured dataset. It covers data preprocessing, feature engineering, model training, evaluation, and insights interpretation.

## ðŸš€ Project Overview

The goal is to compare the performance of various classification models:

- **K-Nearest Neighbors (KNN)**
- **Support Vector Machine (SVM)**
- **Decision Tree**
- **Random Forest**
- **XGBoost**
-  **Regression lineaire**
- **K-Means**


The dataset is carefully preprocessed to ensure the highest model efficiency, including handling missing values, feature scaling, and label encoding.

## ðŸ§  Machine Learning Workflow

1. **Data Cleaning and Preparation**
   - Handling missing values
   - Feature selection
   - Data normalization and encoding

2. **Model Training and Evaluation**
   - Splitting data into training and test sets
   - Training each model
   - Evaluating performance using metrics such as Accuracy, Precision, Recall, F1-Score

3. **Model Comparison**
   - Visualizing the performance of all models
   - Discussing strengths and weaknesses

## ðŸ“Š Technologies Used

- Python 3
- Scikit-Learn
- XGBoost
- Pandas
- Numpy
- Matplotlib
- Seaborn
- Jupyter Notebook

## ðŸ“ˆ Results Summary

Each model was evaluated based on multiple performance metrics to provide a complete understanding of its strengths and weaknesses.  
The project highlights the importance of model selection and data preparation in the machine learning pipeline.
